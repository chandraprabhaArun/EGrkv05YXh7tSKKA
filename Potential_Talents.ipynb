{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtmoqubVz2A1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from gensim.models import Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch\n",
        "import re\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "from lightgbm import LGBMRanker\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFBhIla_V7VU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2759b2-cb2a-43ef-f72d-26c007469149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Download NLTK resources\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jdw0cOqjfmIT"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/potential-talents - Aspiring human resources - seeking human resources.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIBxyrQfWEIy"
      },
      "outputs": [],
      "source": [
        "# Function to convert \"500+\" to \"500\" and leave the rest unchanged\n",
        "def convert_connection(connection):\n",
        "    if '+' in str(connection):\n",
        "        return int(str(connection).replace('+', ''))\n",
        "    else:\n",
        "        return int(connection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T47hNOZMWRui"
      },
      "outputs": [],
      "source": [
        "# Apply the conversion to the \"connection\" column\n",
        "df['connection'] = df['connection'].apply(convert_connection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKeYULhqWWmK"
      },
      "outputs": [],
      "source": [
        "# Scale the \"connection\" column to the range [0, 1]\n",
        "scaler = MinMaxScaler()\n",
        "df['scaled_connection'] = scaler.fit_transform(df[['connection']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaCOTdxxWamE"
      },
      "outputs": [],
      "source": [
        "# Function for text preprocessing\n",
        "def preprocess_text(text):\n",
        "    words = word_tokenize(text.lower())\n",
        "    words = [word for word in words if word.isalnum()]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    porter_stemmer = PorterStemmer()\n",
        "    words = [porter_stemmer.stem(word) for word in words]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSCpfLzfWej2"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing to each job title\n",
        "df['processed_job_title'] = df['job_title'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQIRlo_JWnab"
      },
      "outputs": [],
      "source": [
        "# Function to tokenize and tag documents\n",
        "def tag_documents(df):\n",
        "    tagged_data = []\n",
        "    for i, row in df.iterrows():\n",
        "        tagged_data.append(TaggedDocument(words=row['processed_job_title'], tags=[str(row.name)]))\n",
        "    return tagged_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vq1iJMQDWqqJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d14faf77-797b-4c5b-f10c-c7605f0b476e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TaggedDocument(words=['2019', 'bauer', 'colleg', 'busi', 'graduat', 'magna', 'cum', 'laud', 'aspir', 'human', 'resourc', 'profession'], tags=['0']), TaggedDocument(words=['nativ', 'english', 'teacher', 'epik', 'english', 'program', 'korea'], tags=['1']), TaggedDocument(words=['aspir', 'human', 'resourc', 'profession'], tags=['2']), TaggedDocument(words=['peopl', 'develop', 'coordin', 'ryan'], tags=['3']), TaggedDocument(words=['advisori', 'board', 'member', 'celal', 'bayar', 'univers'], tags=['4']), TaggedDocument(words=['aspir', 'human', 'resourc', 'specialist'], tags=['5']), TaggedDocument(words=['student', 'humber', 'colleg', 'aspir', 'human', 'resourc', 'generalist'], tags=['6']), TaggedDocument(words=['hr', 'senior', 'specialist'], tags=['7']), TaggedDocument(words=['student', 'humber', 'colleg', 'aspir', 'human', 'resourc', 'generalist'], tags=['8']), TaggedDocument(words=['seek', 'human', 'resourc', 'hri', 'generalist', 'posit'], tags=['9']), TaggedDocument(words=['student', 'chapman', 'univers'], tags=['10']), TaggedDocument(words=['svp', 'chro', 'market', 'commun', 'csr', 'offic', 'engi', 'houston', 'woodland', 'energi', 'gphr', 'sphr'], tags=['11']), TaggedDocument(words=['human', 'resourc', 'coordin', 'intercontinent', 'buckhead', 'atlanta'], tags=['12']), TaggedDocument(words=['2019', 'bauer', 'colleg', 'busi', 'graduat', 'magna', 'cum', 'laud', 'aspir', 'human', 'resourc', 'profession'], tags=['13']), TaggedDocument(words=['2019', 'bauer', 'colleg', 'busi', 'graduat', 'magna', 'cum', 'laud', 'aspir', 'human', 'resourc', 'profession'], tags=['14']), TaggedDocument(words=['nativ', 'english', 'teacher', 'epik', 'english', 'program', 'korea'], tags=['15']), TaggedDocument(words=['aspir', 'human', 'resourc', 'profession'], tags=['16']), TaggedDocument(words=['peopl', 'develop', 'coordin', 'ryan'], tags=['17']), TaggedDocument(words=['2019', 'bauer', 'colleg', 'busi', 'graduat', 'magna', 'cum', 'laud', 'aspir', 'human', 'resourc', 'profession'], tags=['18']), TaggedDocument(words=['nativ', 'english', 'teacher', 'epik', 'english', 'program', 'korea'], tags=['19']), TaggedDocument(words=['aspir', 'human', 'resourc', 'profession'], tags=['20']), TaggedDocument(words=['peopl', 'develop', 'coordin', 'ryan'], tags=['21']), TaggedDocument(words=['advisori', 'board', 'member', 'celal', 'bayar', 'univers'], tags=['22']), TaggedDocument(words=['aspir', 'human', 'resourc', 'specialist'], tags=['23']), TaggedDocument(words=['student', 'humber', 'colleg', 'aspir', 'human', 'resourc', 'generalist'], tags=['24']), TaggedDocument(words=['hr', 'senior', 'specialist'], tags=['25']), TaggedDocument(words=['aspir', 'human', 'resourc', 'manag', 'student', 'seek', 'internship'], tags=['26']), TaggedDocument(words=['seek', 'human', 'resourc', 'opportun'], tags=['27']), TaggedDocument(words=['aspir', 'human', 'resourc', 'manag', 'student', 'seek', 'internship'], tags=['28']), TaggedDocument(words=['seek', 'human', 'resourc', 'opportun'], tags=['29']), TaggedDocument(words=['2019', 'bauer', 'colleg', 'busi', 'graduat', 'magna', 'cum', 'laud', 'aspir', 'human', 'resourc', 'profession'], tags=['30']), TaggedDocument(words=['nativ', 'english', 'teacher', 'epik', 'english', 'program', 'korea'], tags=['31']), TaggedDocument(words=['aspir', 'human', 'resourc', 'profession'], tags=['32']), TaggedDocument(words=['peopl', 'develop', 'coordin', 'ryan'], tags=['33']), TaggedDocument(words=['advisori', 'board', 'member', 'celal', 'bayar', 'univers'], tags=['34']), TaggedDocument(words=['aspir', 'human', 'resourc', 'specialist'], tags=['35']), TaggedDocument(words=['student', 'humber', 'colleg', 'aspir', 'human', 'resourc', 'generalist'], tags=['36']), TaggedDocument(words=['hr', 'senior', 'specialist'], tags=['37']), TaggedDocument(words=['student', 'humber', 'colleg', 'aspir', 'human', 'resourc', 'generalist'], tags=['38']), TaggedDocument(words=['seek', 'human', 'resourc', 'hri', 'generalist', 'posit'], tags=['39']), TaggedDocument(words=['student', 'chapman', 'univers'], tags=['40']), TaggedDocument(words=['svp', 'chro', 'market', 'commun', 'csr', 'offic', 'engi', 'houston', 'woodland', 'energi', 'gphr', 'sphr'], tags=['41']), TaggedDocument(words=['human', 'resourc', 'coordin', 'intercontinent', 'buckhead', 'atlanta'], tags=['42']), TaggedDocument(words=['2019', 'bauer', 'colleg', 'busi', 'graduat', 'magna', 'cum', 'laud', 'aspir', 'human', 'resourc', 'profession'], tags=['43']), TaggedDocument(words=['nativ', 'english', 'teacher', 'epik', 'english', 'program', 'korea'], tags=['44']), TaggedDocument(words=['aspir', 'human', 'resourc', 'profession'], tags=['45']), TaggedDocument(words=['peopl', 'develop', 'coordin', 'ryan'], tags=['46']), TaggedDocument(words=['advisori', 'board', 'member', 'celal', 'bayar', 'univers'], tags=['47']), TaggedDocument(words=['aspir', 'human', 'resourc', 'specialist'], tags=['48']), TaggedDocument(words=['student', 'humber', 'colleg', 'aspir', 'human', 'resourc', 'generalist'], tags=['49']), TaggedDocument(words=['hr', 'senior', 'specialist'], tags=['50']), TaggedDocument(words=['student', 'humber', 'colleg', 'aspir', 'human', 'resourc', 'generalist'], tags=['51']), TaggedDocument(words=['seek', 'human', 'resourc', 'hri', 'generalist', 'posit'], tags=['52']), TaggedDocument(words=['student', 'chapman', 'univers'], tags=['53']), TaggedDocument(words=['svp', 'chro', 'market', 'commun', 'csr', 'offic', 'engi', 'houston', 'woodland', 'energi', 'gphr', 'sphr'], tags=['54']), TaggedDocument(words=['human', 'resourc', 'coordin', 'intercontinent', 'buckhead', 'atlanta'], tags=['55']), TaggedDocument(words=['2019', 'bauer', 'colleg', 'busi', 'graduat', 'magna', 'cum', 'laud', 'aspir', 'human', 'resourc', 'profession'], tags=['56']), TaggedDocument(words=['aspir', 'human', 'resourc', 'profession'], tags=['57']), TaggedDocument(words=['peopl', 'develop', 'coordin', 'ryan'], tags=['58']), TaggedDocument(words=['aspir', 'human', 'resourc', 'specialist'], tags=['59']), TaggedDocument(words=['hr', 'senior', 'specialist'], tags=['60']), TaggedDocument(words=['seek', 'human', 'resourc', 'hri', 'generalist', 'posit'], tags=['61']), TaggedDocument(words=['student', 'chapman', 'univers'], tags=['62']), TaggedDocument(words=['svp', 'chro', 'market', 'commun', 'csr', 'offic', 'engi', 'houston', 'woodland', 'energi', 'gphr', 'sphr'], tags=['63']), TaggedDocument(words=['human', 'resourc', 'coordin', 'intercontinent', 'buckhead', 'atlanta'], tags=['64']), TaggedDocument(words=['experienc', 'retail', 'manag', 'aspir', 'human', 'resourc', 'profession'], tags=['65']), TaggedDocument(words=['human', 'resourc', 'staf', 'recruit', 'profession'], tags=['66']), TaggedDocument(words=['human', 'resourc', 'specialist', 'luxottica'], tags=['67']), TaggedDocument(words=['director', 'human', 'resourc', 'north', 'america', 'group', 'beneteau'], tags=['68']), TaggedDocument(words=['retir', 'armi', 'nation', 'guard', 'recruit', 'offic', 'manag', 'seek', 'posit', 'human', 'resourc'], tags=['69']), TaggedDocument(words=['human', 'resourc', 'generalist', 'scottmadden', 'inc'], tags=['70']), TaggedDocument(words=['busi', 'manag', 'major', 'aspir', 'human', 'resourc', 'manag'], tags=['71']), TaggedDocument(words=['aspir', 'human', 'resourc', 'manag', 'seek', 'internship', 'human', 'resourc'], tags=['72']), TaggedDocument(words=['human', 'resourc', 'profession'], tags=['73']), TaggedDocument(words=['nortia', 'staf', 'seek', 'human', 'resourc', 'payrol', 'administr', 'profession', '408'], tags=['74']), TaggedDocument(words=['aspir', 'human', 'resourc', 'profession', 'passion', 'help', 'creat', 'inclus', 'engag', 'work', 'environ'], tags=['75']), TaggedDocument(words=['human', 'conflict', 'polici', 'compens'], tags=['76']), TaggedDocument(words=['human', 'resourc', 'generalist', 'schwan'], tags=['77']), TaggedDocument(words=['liber', 'art', 'major', 'aspir', 'human', 'resourc', 'analyst'], tags=['78']), TaggedDocument(words=['junior', 'me', 'inform', 'system'], tags=['79']), TaggedDocument(words=['senior', 'human', 'resourc', 'busi', 'partner', 'heil', 'environment'], tags=['80']), TaggedDocument(words=['aspir', 'human', 'resourc', 'profession', 'energet', 'leader'], tags=['81']), TaggedDocument(words=['hr', 'manag', 'endemol', 'shine', 'north', 'america'], tags=['82']), TaggedDocument(words=['human', 'resourc', 'profession', 'world', 'leader', 'gi', 'softwar'], tags=['83']), TaggedDocument(words=['rrp', 'brand', 'portfolio', 'execut', 'jti', 'japan', 'tobacco', 'intern'], tags=['84']), TaggedDocument(words=['inform', 'system', 'specialist', 'programm', 'love', 'data', 'organ'], tags=['85']), TaggedDocument(words=['bachelor', 'scienc', 'biolog', 'victoria', 'univers', 'wellington'], tags=['86']), TaggedDocument(words=['human', 'resourc', 'manag', 'major'], tags=['87']), TaggedDocument(words=['director', 'human', 'resourc', 'ey'], tags=['88']), TaggedDocument(words=['undergradu', 'research', 'assist', 'styczynski', 'lab'], tags=['89']), TaggedDocument(words=['lead', 'offici', 'western', 'illinoi', 'univers'], tags=['90']), TaggedDocument(words=['seek', 'employ', 'opportun', 'within', 'custom', 'servic', 'patient', 'care'], tags=['91']), TaggedDocument(words=['admiss', 'repres', 'commun', 'medic', 'center', 'long', 'beach'], tags=['92']), TaggedDocument(words=['seek', 'human', 'resourc', 'opportun', 'open', 'travel', 'reloc'], tags=['93']), TaggedDocument(words=['student', 'westfield', 'state', 'univers'], tags=['94']), TaggedDocument(words=['student', 'indiana', 'univers', 'kokomo', 'busi', 'manag', 'retail', 'manag', 'delphi', 'hardwar', 'paint'], tags=['95']), TaggedDocument(words=['aspir', 'human', 'resourc', 'profession'], tags=['96']), TaggedDocument(words=['student'], tags=['97']), TaggedDocument(words=['seek', 'human', 'resourc', 'posit'], tags=['98']), TaggedDocument(words=['aspir', 'human', 'resourc', 'manag', 'graduat', 'may', '2020', 'seek', 'human', 'resourc', 'posit', 'loui'], tags=['99']), TaggedDocument(words=['human', 'resourc', 'generalist', 'loparex'], tags=['100']), TaggedDocument(words=['busi', 'intellig', 'analyt', 'travel'], tags=['101']), TaggedDocument(words=['alway', 'set', 'success'], tags=['102']), TaggedDocument(words=['director', 'administr', 'excel', 'log'], tags=['103'])]\n"
          ]
        }
      ],
      "source": [
        "# Tokenize and tag documents\n",
        "tagged_data = tag_documents(df)\n",
        "print(tagged_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7v3q5R9WuHz"
      },
      "outputs": [],
      "source": [
        "# Train a Doc2Vec model\n",
        "model = Doc2Vec(vector_size=50, window=2, min_count=1, workers=4, epochs=100)\n",
        "model.build_vocab(tagged_data)\n",
        "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7rwHsWDW4Kz"
      },
      "outputs": [],
      "source": [
        "# Get the embedding for \"Aspiring human resources\" (w1)\n",
        "w1 = 'Aspiring human resources'\n",
        "vector_w1 = model.infer_vector(preprocess_text(w1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOF2kUepPsvU"
      },
      "outputs": [],
      "source": [
        "# Add another word \"seeking human resources\" (w2)\n",
        "w2 = 'Seeking human resources'\n",
        "vector_w2 = model.infer_vector(preprocess_text(w2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mct2HjPpnZgS"
      },
      "outputs": [],
      "source": [
        "# Calculate cosine similarity between w1 and w2\n",
        "similarity_w1_w2 = cosine_similarity([vector_w1], [vector_w2])[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5EpvQ5LnOnE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db078d91-74f9-41c7-996c-2e3d4ef83aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity between \"Aspiring human resources\" and \"Seeking human resources\": 0.9877694845199585\n"
          ]
        }
      ],
      "source": [
        "# Print the cosine similarity between w1 and w2\n",
        "print(f'Cosine Similarity between \"{w1}\" and \"{w2}\": {similarity_w1_w2}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LFvCimLZdDU"
      },
      "outputs": [],
      "source": [
        " # Calculate cosine similarity between w1, w2, and each job title\n",
        "similarities_w1 = []\n",
        "similarities_w2 = []\n",
        "for i, row in df.iterrows():\n",
        "    title = row['job_title']\n",
        "    vector_title = model.infer_vector(preprocess_text(title))\n",
        "    similarity_w1 = cosine_similarity([vector_w1], [vector_title])[0][0]\n",
        "    similarity_w2 = cosine_similarity([vector_w2], [vector_title])[0][0]\n",
        "    similarities_w1.append(similarity_w1)\n",
        "    similarities_w2.append(similarity_w2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WANsIOPcZjC6"
      },
      "outputs": [],
      "source": [
        "# Add cosine similarities to the DataFrame\n",
        "df['cosine_similarity_w1'] = similarities_w1\n",
        "df['cosine_similarity_w2'] = similarities_w2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETtLEcWsoohB"
      },
      "outputs": [],
      "source": [
        "# Weighted sum of cosine_similarity and scaled_connection\n",
        "weight_cosine = 0.8\n",
        "weight_connection = 0.2\n",
        "df['ranking_w1'] = weight_cosine * df['cosine_similarity_w1'] + weight_connection * df['scaled_connection']\n",
        "df['ranking_w2'] = weight_cosine * df['cosine_similarity_w2'] + weight_connection * df['scaled_connection']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXypwXkqotGy"
      },
      "outputs": [],
      "source": [
        "# Sort the DataFrame based on the \"ranking_w1\" column in descending order\n",
        "df_sorted = df.sort_values(by='ranking_w1', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaYsXJePRNIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e26edf-83fb-4e94-eccb-937081081199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             job_title  scaled_connection  \\\n",
            "84   RRP Brand Portfolio Executive at JTI (Japan To...           1.000000   \n",
            "70     Human Resources Generalist at ScottMadden, Inc.           1.000000   \n",
            "100              Human Resources Generalist at Loparex           1.000000   \n",
            "77              Human Resources Generalist at Schwan's           1.000000   \n",
            "67             Human Resources Specialist at Luxottica           1.000000   \n",
            "..                                                 ...                ...   \n",
            "0    2019 C.T. Bauer College of Business Graduate (...           0.168337   \n",
            "30   2019 C.T. Bauer College of Business Graduate (...           0.168337   \n",
            "14   2019 C.T. Bauer College of Business Graduate (...           0.168337   \n",
            "18   2019 C.T. Bauer College of Business Graduate (...           0.168337   \n",
            "56   2019 C.T. Bauer College of Business Graduate (...           0.168337   \n",
            "\n",
            "     cosine_similarity_w1  cosine_similarity_w2  ranking_w1  ranking_w2  \n",
            "84               0.990403              0.990034    0.992323    0.992027  \n",
            "70               0.990145              0.990039    0.992116    0.992031  \n",
            "100              0.989984              0.991118    0.991987    0.992894  \n",
            "77               0.989607              0.991005    0.991686    0.992804  \n",
            "67               0.989490              0.989132    0.991592    0.991305  \n",
            "..                    ...                   ...         ...         ...  \n",
            "0                0.927873              0.926990    0.775966    0.775260  \n",
            "30               0.922190              0.922601    0.771420    0.771748  \n",
            "14               0.916309              0.916223    0.766714    0.766646  \n",
            "18               0.907106              0.907546    0.759353    0.759704  \n",
            "56               0.888979              0.890087    0.744850    0.745737  \n",
            "\n",
            "[104 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "# Print the sorted DataFrame\n",
        "print(df_sorted[['job_title', 'scaled_connection', 'cosine_similarity_w1', 'cosine_similarity_w2', 'ranking_w1', 'ranking_w2']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYRyEAgGkGDc"
      },
      "source": [
        "### Adding Bert Embeddings_Doctovec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmxsvQdvGst9",
        "outputId": "fb8df4d8-f538-489c-940b-cdeb19c947f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcHyYkR-G2cv"
      },
      "outputs": [],
      "source": [
        "# Tokenize and tag documents for Doc2Vec\n",
        "tagged_data_doc2vec = tag_documents(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0pGQhXdHEF7"
      },
      "outputs": [],
      "source": [
        "# Train a Doc2Vec model\n",
        "model_doc2vec = Doc2Vec(vector_size=50, window=2, min_count=1, workers=4, epochs=100)\n",
        "model_doc2vec.build_vocab(tagged_data_doc2vec)\n",
        "model_doc2vec.train(tagged_data_doc2vec, total_examples=model_doc2vec.corpus_count, epochs=model_doc2vec.epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtEGtDrTHKXu"
      },
      "outputs": [],
      "source": [
        "# Get the embeddings for \"Aspiring human resources\" and \"Seeking human resources\"\n",
        "w1_doc2vec = model_doc2vec.infer_vector(preprocess_text('Aspiring human resources'))\n",
        "w2_doc2vec = model_doc2vec.infer_vector(preprocess_text('Seeking human resources'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EubqxV8gHcxv"
      },
      "outputs": [],
      "source": [
        "# Calculate cosine similarity between w1_doc2vec and w2_doc2vec\n",
        "cosine_similarity_doc2vec = cosine_similarity([w1_doc2vec], [w2_doc2vec])[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGAjm-ukHuc-"
      },
      "outputs": [],
      "source": [
        "# Add cosine similarities to the DataFrame\n",
        "df['cosine_similarity_doc2vec'] = cosine_similarity_doc2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8nvgPkpIQzY"
      },
      "outputs": [],
      "source": [
        "df['scaled_connection_doc2vec'] = MinMaxScaler().fit_transform(df[['connection']])\n",
        "df['ranking_doc2vec'] = 0.8 * df['cosine_similarity_doc2vec'] + 0.2 * df['scaled_connection_doc2vec']\n",
        "df_sorted_doc2vec = df.sort_values(by='ranking_doc2vec', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1bZYbeXIW9t",
        "outputId": "01ce62d4-faec-49b3-8ab0-4572a8f5e436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with Doc2Vec embeddings:\n",
            "                                            job_title  connection  \\\n",
            "52  Seeking Human Resources HRIS and Generalist Po...         500   \n",
            "58             People Development Coordinator at Ryan         500   \n",
            "34    Advisory Board Member at Celal Bayar University         500   \n",
            "37                               HR Senior Specialist         500   \n",
            "39  Seeking Human Resources HRIS and Generalist Po...         500   \n",
            "..                                                ...         ...   \n",
            "48                Aspiring Human Resources Specialist           1   \n",
            "35                Aspiring Human Resources Specialist           1   \n",
            "59                Aspiring Human Resources Specialist           1   \n",
            "5                 Aspiring Human Resources Specialist           1   \n",
            "23                Aspiring Human Resources Specialist           1   \n",
            "\n",
            "    cosine_similarity_doc2vec  ranking_doc2vec  \n",
            "52                   0.987769         0.990216  \n",
            "58                   0.987769         0.990216  \n",
            "34                   0.987769         0.990216  \n",
            "37                   0.987769         0.990216  \n",
            "39                   0.987769         0.990216  \n",
            "..                        ...              ...  \n",
            "48                   0.987769         0.790216  \n",
            "35                   0.987769         0.790216  \n",
            "59                   0.987769         0.790216  \n",
            "5                    0.987769         0.790216  \n",
            "23                   0.987769         0.790216  \n",
            "\n",
            "[104 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "# Display the DataFrame with Doc2Vec embeddings\n",
        "print(\"DataFrame with Doc2Vec embeddings:\")\n",
        "print(df_sorted_doc2vec[['job_title', 'connection', 'cosine_similarity_doc2vec', 'ranking_doc2vec']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ehfm6dFTIfiG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddcdd5d4-a0e7-4848-9014-81f9fbbbad08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# For BERT embeddings, need a pretrained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model_bert = BertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPO9TKdoImwo"
      },
      "outputs": [],
      "source": [
        "# Function to get BERT embeddings\n",
        "def get_bert_embedding(text):\n",
        "    tokens = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        output = model_bert(**tokens)\n",
        "    return output.pooler_output.numpy().squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VLNZ-fKI6u0"
      },
      "outputs": [],
      "source": [
        "# Get BERT embeddings for \"Aspiring human resources\" and \"Seeking human resources\"\n",
        "w1_bert = get_bert_embedding('Aspiring human resources')\n",
        "w2_bert = get_bert_embedding('Seeking human resources')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIOivvpDI_0v"
      },
      "outputs": [],
      "source": [
        "# Calculate cosine similarity between w1_bert and w2_bert\n",
        "cosine_similarity_bert = cosine_similarity([w1_bert], [w2_bert])[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXCb_LPUJQdT"
      },
      "outputs": [],
      "source": [
        "# Add cosine similarities to the DataFrame\n",
        "df['cosine_similarity_bert'] = cosine_similarity_bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BONrJhjiJYGN"
      },
      "outputs": [],
      "source": [
        "df['scaled_connection_bert'] = MinMaxScaler().fit_transform(df[['connection']])\n",
        "df['ranking_bert'] = 0.8 * df['cosine_similarity_bert'] + 0.2 * df['scaled_connection_bert']\n",
        "df_sorted_bert = df.sort_values(by='ranking_bert', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kfjTudIJfkb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b55142-5749-4a0a-a18a-9b5344105cd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame with BERT embeddings:\n",
            "                                            job_title  connection  \\\n",
            "52  Seeking Human Resources HRIS and Generalist Po...         500   \n",
            "58             People Development Coordinator at Ryan         500   \n",
            "34    Advisory Board Member at Celal Bayar University         500   \n",
            "37                               HR Senior Specialist         500   \n",
            "39  Seeking Human Resources HRIS and Generalist Po...         500   \n",
            "..                                                ...         ...   \n",
            "48                Aspiring Human Resources Specialist           1   \n",
            "35                Aspiring Human Resources Specialist           1   \n",
            "59                Aspiring Human Resources Specialist           1   \n",
            "5                 Aspiring Human Resources Specialist           1   \n",
            "23                Aspiring Human Resources Specialist           1   \n",
            "\n",
            "    cosine_similarity_bert  ranking_bert  \n",
            "52                0.990385      0.992308  \n",
            "58                0.990385      0.992308  \n",
            "34                0.990385      0.992308  \n",
            "37                0.990385      0.992308  \n",
            "39                0.990385      0.992308  \n",
            "..                     ...           ...  \n",
            "48                0.990385      0.792308  \n",
            "35                0.990385      0.792308  \n",
            "59                0.990385      0.792308  \n",
            "5                 0.990385      0.792308  \n",
            "23                0.990385      0.792308  \n",
            "\n",
            "[104 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "# Display the DataFrame with BERT embeddings\n",
        "print(\"\\nDataFrame with BERT embeddings:\")\n",
        "print(df_sorted_bert[['job_title', 'connection', 'cosine_similarity_bert', 'ranking_bert']])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Bert Embeddings for sentencetovec"
      ],
      "metadata": {
        "id": "mTBYdaOlB2wm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p4R8HgibA1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c938401-dfc0-4d82-8e8c-869b3767c77f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBB6E2ck6WMG"
      },
      "outputs": [],
      "source": [
        "# BERT Model and Tokenizer\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWpmQK66_v77"
      },
      "outputs": [],
      "source": [
        " #Function to get BERT embeddings for a sentence\n",
        "def get_bert_embedding(sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    return outputs['last_hidden_state'].mean(dim=1).squeeze().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF7UyL8U9Haz"
      },
      "outputs": [],
      "source": [
        "# Function to get BERT embeddings for a given text\n",
        "def get_bert_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)  # Using mean of hidden states as embeddings\n",
        "    return embeddings.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ItzMKp24e57"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EycWE_E-bn8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb8ef402-673c-49ff-e93e-8c182ee8a682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name distilbert-base-uncased. Creating a new one with MEAN pooling.\n"
          ]
        }
      ],
      "source": [
        "# BERT model for sentence embeddings\n",
        "model = SentenceTransformer('distilbert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p25JZXQ9brt5"
      },
      "outputs": [],
      "source": [
        "# Function for calculating cosine similarity between two sentences\n",
        "def calculate_cosine_similarity(sentence1, sentence2):\n",
        "    embeddings = model.encode([sentence1, sentence2], convert_to_tensor=True)\n",
        "    similarity = cosine_similarity(embeddings[0].reshape(1, -1), embeddings[1].reshape(1, -1))[0][0]\n",
        "    return similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38NvvhqEb5Oa"
      },
      "outputs": [],
      "source": [
        "# Get BERT embeddings for \"Aspiring human resources\" and \"Seeking human resources\"\n",
        "w1 = 'Aspiring human resources'\n",
        "w2 = 'Seeking human resources'\n",
        "bert_embedding_w1 = model.encode(w1, convert_to_tensor=True)\n",
        "bert_embedding_w2 = model.encode(w2, convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYsRERVkb8ia"
      },
      "outputs": [],
      "source": [
        "# Calculate cosine similarity between w1, w2, and each job title\n",
        "similarities_w1 = []\n",
        "similarities_w2 = []\n",
        "for i, row in df.iterrows():\n",
        "    title = row['job_title']\n",
        "    bert_embedding_title = model.encode(title, convert_to_tensor=True)\n",
        "    similarity_w1 = cosine_similarity(bert_embedding_w1.reshape(1, -1), bert_embedding_title.reshape(1, -1))[0][0]\n",
        "    similarity_w2 = cosine_similarity(bert_embedding_w2.reshape(1, -1), bert_embedding_title.reshape(1, -1))[0][0]\n",
        "    similarities_w1.append(similarity_w1)\n",
        "    similarities_w2.append(similarity_w2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNcOSJjyb_hq"
      },
      "outputs": [],
      "source": [
        "# Add cosine similarities to the DataFrame\n",
        "df['cosine_similarity_bert_w1'] = similarities_w1\n",
        "df['cosine_similarity_bert_w2'] = similarities_w2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd_U5TSvcCVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db4cbea-1dc5-4118-9306-c929be48e480"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             job_title  connection  \\\n",
            "0    2019 C.T. Bauer College of Business Graduate (...          85   \n",
            "1    Native English Teacher at EPIK (English Progra...         500   \n",
            "2                Aspiring Human Resources Professional          44   \n",
            "3               People Development Coordinator at Ryan         500   \n",
            "4      Advisory Board Member at Celal Bayar University         500   \n",
            "..                                                 ...         ...   \n",
            "99   Aspiring Human Resources Manager | Graduating ...         103   \n",
            "100              Human Resources Generalist at Loparex         500   \n",
            "101   Business Intelligence and Analytics at Travelers          49   \n",
            "102                     Always set them up for Success         500   \n",
            "103   Director Of Administration at Excellence Logging         500   \n",
            "\n",
            "     cosine_similarity_bert_w1  cosine_similarity_bert_w2  \n",
            "0                     0.700951                   0.642038  \n",
            "1                     0.621738                   0.585436  \n",
            "2                     0.947544                   0.864692  \n",
            "3                     0.832818                   0.789346  \n",
            "4                     0.566570                   0.566413  \n",
            "..                         ...                        ...  \n",
            "99                    0.737103                   0.676403  \n",
            "100                   0.774889                   0.741194  \n",
            "101                   0.781910                   0.732494  \n",
            "102                   0.711116                   0.707239  \n",
            "103                   0.801430                   0.743476  \n",
            "\n",
            "[104 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "# Print the DataFrame with job title, connection, and cosine similarities\n",
        "print(df[['job_title', 'connection', 'cosine_similarity_bert_w1', 'cosine_similarity_bert_w2']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPHS2sC9UAfa"
      },
      "outputs": [],
      "source": [
        "# Define weights for different components (adjust based on our preferences)\n",
        "weight_connection = 0.12\n",
        "weight_cosine_w1 = 0.22\n",
        "weight_cosine_w2 = 0.22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jxZlBacUwGZ"
      },
      "outputs": [],
      "source": [
        "# Add cosine similarities to the DataFrame\n",
        "df['cosine_similarity_w1'] = similarities_w1\n",
        "df['cosine_similarity_w2'] = similarities_w2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q68d6UIDcBOh"
      },
      "outputs": [],
      "source": [
        "# Calculate fitness score\n",
        "df['fitness_score'] = (\n",
        "    weight_connection * df['scaled_connection'] +\n",
        "    weight_cosine_w1 * df['cosine_similarity_bert_w1'] +\n",
        "    weight_cosine_w2 * df['cosine_similarity_bert_w2'] +\n",
        "    weight_cosine_w1 * df['cosine_similarity_w1'] +\n",
        "    weight_cosine_w2 * df['cosine_similarity_w2']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fg4FmMxHdX4U"
      },
      "outputs": [],
      "source": [
        "# Rank candidates based on fitness score\n",
        "df['rank'] = df['fitness_score'].rank(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXXY2_9SlXV-"
      },
      "outputs": [],
      "source": [
        "# Sort the DataFrame based on fitness score in descending order\n",
        "df_sorted = df.sort_values(by='fitness_score', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjQgDnz4dacO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "989e6949-8d69-4373-ce1b-15b00602079b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            job_title  connection  \\\n",
            "29              Seeking Human Resources Opportunities         390   \n",
            "27              Seeking Human Resources Opportunities         390   \n",
            "9   Seeking Human Resources HRIS and Generalist Po...         500   \n",
            "39  Seeking Human Resources HRIS and Generalist Po...         500   \n",
            "61  Seeking Human Resources HRIS and Generalist Po...         500   \n",
            "..                                                ...         ...   \n",
            "90       Lead Official at Western Illinois University          39   \n",
            "89  Undergraduate Research Assistant at Styczynski...         155   \n",
            "92  Admissions Representative at Community medical...           9   \n",
            "95  Student at Indiana University Kokomo - Busines...          19   \n",
            "86  Bachelor of Science in Biology from Victoria U...          40   \n",
            "\n",
            "    cosine_similarity_bert_w1  cosine_similarity_bert_w2  fitness_score   rank  \n",
            "29                   0.929482                   0.961083       0.925396    1.5  \n",
            "27                   0.929482                   0.961083       0.925396    1.5  \n",
            "9                    0.829019                   0.809323       0.840870    4.5  \n",
            "39                   0.829019                   0.809323       0.840870    4.5  \n",
            "61                   0.829019                   0.809323       0.840870    4.5  \n",
            "..                        ...                        ...            ...    ...  \n",
            "90                   0.660476                   0.631768       0.577726  100.0  \n",
            "89                   0.604449                   0.577733       0.557194  101.0  \n",
            "92                   0.613595                   0.622983       0.546018  102.0  \n",
            "95                   0.623813                   0.575256       0.531919  103.0  \n",
            "86                   0.497693                   0.486975       0.442632  104.0  \n",
            "\n",
            "[104 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "# Print the sorted DataFrame with fitness score and rank\n",
        "print(df_sorted[['job_title', 'connection', 'cosine_similarity_bert_w1', 'cosine_similarity_bert_w2', 'fitness_score', 'rank']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd232jwfuB6l"
      },
      "outputs": [],
      "source": [
        "# Suppose candidate with index 1 is starred, update its scores\n",
        "\n",
        "starred_candidate_index = 1\n",
        "df.at[starred_candidate_index, 'connection'] = 600  # Update connection score\n",
        "df.at[starred_candidate_index, 'cosine_similarity_bert_w1'] = 0.9  # Update cosine similarity score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LH_W4anLuUVc"
      },
      "outputs": [],
      "source": [
        "# Recalculate fitness score\n",
        "df.at[starred_candidate_index, 'fitness_score'] = (\n",
        "    weight_connection * df.at[starred_candidate_index, 'connection'] +\n",
        "    weight_cosine_w1 * df.at[starred_candidate_index, 'cosine_similarity_bert_w1'] +\n",
        "    weight_cosine_w2 * df.at[starred_candidate_index, 'cosine_similarity_bert_w2']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46BknPutulNB"
      },
      "outputs": [],
      "source": [
        "# Recalculate rank\n",
        "df['rank'] = df['fitness_score'].rank(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YtE0h3CuoE2"
      },
      "outputs": [],
      "source": [
        "# Re-sort the DataFrame based on fitness score in descending order\n",
        "df = df.sort_values(by='fitness_score', ascending=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "bmCM44o3oZdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Applying LambdaMART with LightGBM\n",
        "\n"
      ],
      "metadata": {
        "id": "9OQ9JvS-frUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['rank']= 0"
      ],
      "metadata": {
        "id": "Qe43QuFNmdzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[:9, 'rank'] = 1"
      ],
      "metadata": {
        "id": "WYm0GlhmnBRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "ln4PemcZnEfz",
        "outputId": "4fae966b-81ef-4f3e-b00c-92d819bd9143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                          job_title  \\\n",
              "0   2  Native English Teacher at EPIK (English Progra...   \n",
              "1  30              Seeking Human Resources Opportunities   \n",
              "2  28              Seeking Human Resources Opportunities   \n",
              "3  10  Seeking Human Resources HRIS and Generalist Po...   \n",
              "4  40  Seeking Human Resources HRIS and Generalist Po...   \n",
              "\n",
              "                    location  connection  fit  scaled_connection  \\\n",
              "0                     Kanada         600  NaN           1.000000   \n",
              "1          Chicago, Illinois         390  NaN           0.779559   \n",
              "2          Chicago, Illinois         390  NaN           0.779559   \n",
              "3  Greater Philadelphia Area         500  NaN           1.000000   \n",
              "4  Greater Philadelphia Area         500  NaN           1.000000   \n",
              "\n",
              "                                 processed_job_title  cosine_similarity_w1  \\\n",
              "0  [nativ, english, teacher, epik, english, progr...              0.621738   \n",
              "1                   [seek, human, resourc, opportun]              0.929482   \n",
              "2                   [seek, human, resourc, opportun]              0.929482   \n",
              "3     [seek, human, resourc, hri, generalist, posit]              0.829019   \n",
              "4     [seek, human, resourc, hri, generalist, posit]              0.829019   \n",
              "\n",
              "   cosine_similarity_w2  ranking_w1  ...  cosine_similarity_doc2vec  \\\n",
              "0              0.585436    0.900059  ...                   0.987769   \n",
              "1              0.961083    0.945860  ...                   0.987769   \n",
              "2              0.961083    0.946539  ...                   0.987769   \n",
              "3              0.809323    0.982802  ...                   0.987769   \n",
              "4              0.809323    0.985377  ...                   0.987769   \n",
              "\n",
              "   scaled_connection_doc2vec  ranking_doc2vec  cosine_similarity_bert  \\\n",
              "0                   1.000000         0.990216                0.990385   \n",
              "1                   0.779559         0.946127                0.990385   \n",
              "2                   0.779559         0.946127                0.990385   \n",
              "3                   1.000000         0.990216                0.990385   \n",
              "4                   1.000000         0.990216                0.990385   \n",
              "\n",
              "   scaled_connection_bert  ranking_bert  cosine_similarity_bert_w1  \\\n",
              "0                1.000000      0.992308                   0.900000   \n",
              "1                0.779559      0.948219                   0.929482   \n",
              "2                0.779559      0.948219                   0.929482   \n",
              "3                1.000000      0.992308                   0.829019   \n",
              "4                1.000000      0.992308                   0.829019   \n",
              "\n",
              "   cosine_similarity_bert_w2  fitness_score  rank  \n",
              "0                   0.585436      72.326796     1  \n",
              "1                   0.961083       0.925396     1  \n",
              "2                   0.961083       0.925396     1  \n",
              "3                   0.809323       0.840870     1  \n",
              "4                   0.809323       0.840870     1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3948ca7a-de77-4204-90d9-75e9e535471b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>job_title</th>\n",
              "      <th>location</th>\n",
              "      <th>connection</th>\n",
              "      <th>fit</th>\n",
              "      <th>scaled_connection</th>\n",
              "      <th>processed_job_title</th>\n",
              "      <th>cosine_similarity_w1</th>\n",
              "      <th>cosine_similarity_w2</th>\n",
              "      <th>ranking_w1</th>\n",
              "      <th>...</th>\n",
              "      <th>cosine_similarity_doc2vec</th>\n",
              "      <th>scaled_connection_doc2vec</th>\n",
              "      <th>ranking_doc2vec</th>\n",
              "      <th>cosine_similarity_bert</th>\n",
              "      <th>scaled_connection_bert</th>\n",
              "      <th>ranking_bert</th>\n",
              "      <th>cosine_similarity_bert_w1</th>\n",
              "      <th>cosine_similarity_bert_w2</th>\n",
              "      <th>fitness_score</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
              "      <td>Kanada</td>\n",
              "      <td>600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>[nativ, english, teacher, epik, english, progr...</td>\n",
              "      <td>0.621738</td>\n",
              "      <td>0.585436</td>\n",
              "      <td>0.900059</td>\n",
              "      <td>...</td>\n",
              "      <td>0.987769</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.990216</td>\n",
              "      <td>0.990385</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.992308</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.585436</td>\n",
              "      <td>72.326796</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30</td>\n",
              "      <td>Seeking Human Resources Opportunities</td>\n",
              "      <td>Chicago, Illinois</td>\n",
              "      <td>390</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.779559</td>\n",
              "      <td>[seek, human, resourc, opportun]</td>\n",
              "      <td>0.929482</td>\n",
              "      <td>0.961083</td>\n",
              "      <td>0.945860</td>\n",
              "      <td>...</td>\n",
              "      <td>0.987769</td>\n",
              "      <td>0.779559</td>\n",
              "      <td>0.946127</td>\n",
              "      <td>0.990385</td>\n",
              "      <td>0.779559</td>\n",
              "      <td>0.948219</td>\n",
              "      <td>0.929482</td>\n",
              "      <td>0.961083</td>\n",
              "      <td>0.925396</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>Seeking Human Resources Opportunities</td>\n",
              "      <td>Chicago, Illinois</td>\n",
              "      <td>390</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.779559</td>\n",
              "      <td>[seek, human, resourc, opportun]</td>\n",
              "      <td>0.929482</td>\n",
              "      <td>0.961083</td>\n",
              "      <td>0.946539</td>\n",
              "      <td>...</td>\n",
              "      <td>0.987769</td>\n",
              "      <td>0.779559</td>\n",
              "      <td>0.946127</td>\n",
              "      <td>0.990385</td>\n",
              "      <td>0.779559</td>\n",
              "      <td>0.948219</td>\n",
              "      <td>0.929482</td>\n",
              "      <td>0.961083</td>\n",
              "      <td>0.925396</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>Seeking Human Resources HRIS and Generalist Po...</td>\n",
              "      <td>Greater Philadelphia Area</td>\n",
              "      <td>500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>[seek, human, resourc, hri, generalist, posit]</td>\n",
              "      <td>0.829019</td>\n",
              "      <td>0.809323</td>\n",
              "      <td>0.982802</td>\n",
              "      <td>...</td>\n",
              "      <td>0.987769</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.990216</td>\n",
              "      <td>0.990385</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.992308</td>\n",
              "      <td>0.829019</td>\n",
              "      <td>0.809323</td>\n",
              "      <td>0.840870</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40</td>\n",
              "      <td>Seeking Human Resources HRIS and Generalist Po...</td>\n",
              "      <td>Greater Philadelphia Area</td>\n",
              "      <td>500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>[seek, human, resourc, hri, generalist, posit]</td>\n",
              "      <td>0.829019</td>\n",
              "      <td>0.809323</td>\n",
              "      <td>0.985377</td>\n",
              "      <td>...</td>\n",
              "      <td>0.987769</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.990216</td>\n",
              "      <td>0.990385</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.992308</td>\n",
              "      <td>0.829019</td>\n",
              "      <td>0.809323</td>\n",
              "      <td>0.840870</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3948ca7a-de77-4204-90d9-75e9e535471b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3948ca7a-de77-4204-90d9-75e9e535471b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3948ca7a-de77-4204-90d9-75e9e535471b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1474d2bb-e4cb-47b4-9fea-cd67910d459d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1474d2bb-e4cb-47b4-9fea-cd67910d459d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1474d2bb-e4cb-47b4-9fea-cd67910d459d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features and labels\n",
        "X = df[['cosine_similarity_w1', 'cosine_similarity_w2', 'cosine_similarity_bert_w1', 'cosine_similarity_bert_w2']]\n",
        "y = df['rank']\n"
      ],
      "metadata": {
        "id": "T-gAs7t9cV-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "cOk4Q_H2c7dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert data to LightGBM Dataset format\n",
        "train_data = lgb.Dataset(X_train, label=y_train, group=[len(X_train)])\n",
        "test_data = lgb.Dataset(X_test, label=y_test, group=[len(X_test)])"
      ],
      "metadata": {
        "id": "I1B7CXaAc9zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters for LambdaMART\n",
        "params = {\n",
        "    'objective': 'lambdarank',\n",
        "    'metric': 'ndcg',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'learning_rate': 0.1,\n",
        "    'num_leaves': 31,\n",
        "    'min_data_in_leaf': 1,\n",
        "    'num_iterations': 100,\n",
        "    'verbose': 0\n",
        "}\n"
      ],
      "metadata": {
        "id": "Db_NzCGEdAFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the LambdaMART model\n",
        "ranker_model = lgb.train(params, train_data, valid_sets=[test_data])\n",
        "\n",
        "# Save the model (optional)\n",
        "ranker_model.save_model('lambdamart_model.txt')\n",
        "\n",
        "# Predict on the test set\n",
        "predictions = ranker_model.predict(X_test)\n",
        "\n",
        "# Display the predictions\n",
        "print(\"Predictions:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe0Jz3hAdCmx",
        "outputId": "aabad513-926d-4315-a895-090ab9d64be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Predictions: [-6.05184504 -6.05346867 -6.05565758 -6.0562113  -6.05064861 -6.05588588\n",
            " -6.05494591 -2.2464472   0.74724703 -6.05346867 -4.11553845 -6.05183129\n",
            " -6.05494591 -6.05588588 -6.05248139  5.24031901 -6.05373587  5.13807928\n",
            "  0.74724703 -2.87643046 -6.05494591]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}